import time  
import streamlit as st
import pandas as pd
import re
import jieba
import numpy as np
from pypinyin import lazy_pinyin, Style
from datetime import datetime
from snownlp import SnowNLP
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack
import joblib
import requests
import os
import io
import zipfile
import sqlite3
import bcrypt

# ====================== ç”¨æˆ·è®¤è¯æ¨¡å— ======================
def init_auth_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ï¼ˆæ–°å¢å†å²è®°å½•å­—æ®µï¼‰"""
    conn = sqlite3.connect('user_auth.db', check_same_thread=False)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username TEXT UNIQUE NOT NULL,
            password_hash TEXT NOT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_data (
            data_id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            history_id TEXT NOT NULL,
            upload_time DATETIME DEFAULT CURRENT_TIMESTAMP,
            raw_data BLOB,
            cleaned_data BLOB,
            predicted_data BLOB,
            analysis_report BLOB,
            FOREIGN KEY(user_id) REFERENCES users(id)
        )
    ''')
    conn.commit()
    return conn

@st.cache_resource
def get_auth_db():
    return init_auth_db()

# ====================== æ–°å¢å†å²è®°å½•ç®¡ç†æ¨¡å— ======================
def create_history_entry(user_id):
    """ç”Ÿæˆå”¯ä¸€å†å²è®°å½•IDï¼ˆç½‘é¡µ1ï¼‰"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    return f"{user_id}_{timestamp}"

def save_full_process_data(user_id, history_id, raw_df, cleaned_df, predicted_df, analysis_reports):
    """ä¿å­˜å®Œæ•´åˆ†ææµç¨‹æ•°æ®ï¼ˆç½‘é¡µ3ï¼‰"""
    with sqlite3.connect('user_auth.db', check_same_thread=False) as conn:
        try:
            # åºåˆ—åŒ–æ•°æ®
            raw_buffer = io.BytesIO()
            raw_df.to_parquet(raw_buffer)
            cleaned_buffer = io.BytesIO()
            cleaned_df.to_parquet(cleaned_buffer)
            predicted_buffer = io.BytesIO()
            predicted_df.to_parquet(predicted_buffer)
            
            # å‹ç¼©åˆ†ææŠ¥å‘Šï¼ˆç½‘é¡µ5ï¼‰
            report_buffer = io.BytesIO()
            with zipfile.ZipFile(report_buffer, 'w') as zip_file:
                for product, report in analysis_reports.items():
                    safe_name = re.sub(r'[\\/*?:"<>|]', "_", product)
                    zip_file.writestr(f"{safe_name}_åˆ†æ.txt", report)
            
            # æ’å…¥æ•°æ®åº“ï¼ˆç½‘é¡µ3ï¼‰
            conn.execute('''
                INSERT INTO user_data 
                (user_id, history_id, raw_data, cleaned_data, predicted_data, analysis_report)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (user_id, history_id,
                  raw_buffer.getvalue(),
                  cleaned_buffer.getvalue(),
                  predicted_buffer.getvalue(),
                  report_buffer.getvalue()))
            conn.commit()
            return True
        except Exception as e:
            st.error(f"å†å²ä¿å­˜å¤±è´¥: {str(e)}")
            return False

def load_history_data(user_id, history_id):
    """åŠ è½½å†å²è®°å½•ï¼ˆç½‘é¡µ7ï¼‰"""
    with sqlite3.connect('user_auth.db', check_same_thread=False) as conn:
        result = conn.execute('''
            SELECT raw_data, cleaned_data, predicted_data, analysis_report 
            FROM user_data 
            WHERE user_id = ? AND history_id = ?
        ''', (user_id, history_id)).fetchone()
        
        if result:
            return {
                'raw': pd.read_parquet(io.BytesIO(result[0])),
                'cleaned': pd.read_parquet(io.BytesIO(result[1])),
                'predicted': pd.read_parquet(io.BytesIO(result[2])),
                'report': result[3]
            }
        return None

def get_user_history(user_id):
    """è·å–ç”¨æˆ·å†å²è®°å½•åˆ—è¡¨ï¼ˆç½‘é¡µ2ï¼‰"""
    with sqlite3.connect('user_auth.db', check_same_thread=False) as conn:
        return conn.execute('''
            SELECT DISTINCT history_id, upload_time 
            FROM user_data 
            WHERE user_id = ?
            ORDER BY upload_time DESC
        ''', (user_id,)).fetchall()

def delete_history(user_id, history_id):
    """åˆ é™¤å†å²è®°å½•ï¼ˆç½‘é¡µ4ï¼‰"""
    with sqlite3.connect('user_auth.db', check_same_thread=False) as conn:
        try:
            conn.execute('''
                DELETE FROM user_data 
                WHERE user_id = ? AND history_id = ?
            ''', (user_id, history_id))
            conn.commit()
            return True
        except Exception as e:
            st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")
            return False

# ====================== ä¿®æ”¹åçš„ä¸»ç•Œé¢æ¨¡å— ======================
def main_interface():
    st.title(f"æ¬¢è¿å›æ¥ï¼Œ{st.session_state.username}ï¼")
    
    # å†å²è®°å½•ä¾§è¾¹æ ï¼ˆç½‘é¡µ6ï¼‰
    with st.sidebar:
        st.subheader("ğŸ“œ åˆ†æå†å²")
        history_list = get_user_history(st.session_state.user_id)
        
        if history_list:
            selected_history = st.selectbox(
                "é€‰æ‹©å†å²è®°å½•",
                options=[h[0] for h in history_list],
                format_func=lambda x: datetime.strptime(x.split('_')[1], "%Y%m%d%H%M%S").strftime('%Y-%m-%d %H:%M')
            )
            
            cols = st.columns([3,1])
            with cols[0]:
                if st.button("ğŸ” åŠ è½½å†å²"):
                    history_data = load_history_data(st.session_state.user_id, selected_history)
                    if history_data:
                        st.session_state.update({
                            'raw_df': history_data['raw'],
                            'cleaned_df': history_data['cleaned'],
                            'predicted_df': history_data['predicted'],
                            'analysis_reports': io.BytesIO(history_data['report'])
                        })
                        st.rerun()
            with cols[1]:
                if st.button("ğŸ—‘ åˆ é™¤", type="secondary"):
                    if delete_history(st.session_state.user_id, selected_history):
                        st.success("åˆ é™¤æˆåŠŸ")
                        st.rerun()
        else:
            st.caption("æš‚æ— å†å²è®°å½•")
            
    # æ–‡ä»¶ä¸Šä¼ æ¨¡å—
    uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=["csv"], 
                                    help="æ”¯æŒUTF-8ç¼–ç æ–‡ä»¶ï¼Œæœ€å¤§100MB")
    
    if uploaded_file:
        try:
            raw_df = pd.read_csv(uploaded_file)
            history_id = create_history_entry(st.session_state.user_id)
            conn = get_auth_db()
            conn.execute('''
                INSERT INTO user_data 
                (user_id, history_id, raw_data)
                VALUES (?, ?, ?)
            ''', (st.session_state.user_id, history_id, uploaded_file.getvalue()))
            conn.commit()
            st.session_state.raw_df = raw_df
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    # æ•°æ®å±•ç¤ºæ¨¡å—
    if st.session_state.raw_df is not None:
        with st.expander("ğŸ“‚ åŸå§‹æ•°æ®è¯¦æƒ…", expanded=False):
            st.write(f"è®°å½•æ•°ï¼š{len(st.session_state.raw_df)}")
            st.dataframe(st.session_state.raw_df, use_container_width=True, height=300)
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å½“å‰æ•°æ®"):
                st.session_state.raw_df = None
                st.session_state.cleaned_df = None
                st.session_state.predicted_df = None
                st.rerun()

    # æ•°æ®æ¸…æ´—æ¨¡å—
    if st.session_state.raw_df is not None:
        st.divider()
        st.subheader("æ•°æ®æ¸…æ´—æ¨¡å—")
        
        if st.button("ğŸš€ å¼€å§‹æ¸…æ´—", help="ç‚¹å‡»å¼€å§‹ç‹¬ç«‹æ¸…æ´—æµç¨‹", use_container_width=True):
            with st.spinner('æ­£åœ¨å¤„ç†æ•°æ®...'):
                start_time = time.time()
                cleaned_df = cleaning(st.session_state.raw_df.copy())
                if save_user_data(st.session_state.user_id, 'cleaned_data', cleaned_df):
                    st.session_state.cleaned_df = cleaned_df
                st.session_state.processing_time = time.time() - start_time

        if st.session_state.cleaned_df is not None:
            with st.expander("âœ¨ æ¸…æ´—åæ•°æ®è¯¦æƒ…", expanded=False):
                st.write(f"å”¯ä¸€äº§å“åˆ—è¡¨ï¼š{st.session_state.cleaned_df['äº§å“'].unique().tolist()}")
                st.dataframe(
                    st.session_state.cleaned_df[['æ˜µç§°','æ—¥æœŸ','åœ°åŒº','äº§å“', 'è¯„åˆ†','è¯„è®º']],
                    use_container_width=True,
                    height=400
                )

    # é¢„æµ‹åˆ†ææ¨¡å—
    if st.session_state.cleaned_df is not None:
        st.divider()
        st.subheader("é¢„æµ‹æ¨¡å—")
    
        if st.button("ğŸ”® é¢„æµ‹æ¨èæŒ‡æ•°", use_container_width=True):
            if 'model' not in st.session_state:
                st.error("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ï¼")
                return
        
            cleaned_df = st.session_state.cleaned_df.copy()
        
            with st.status("ğŸ§  æ­£åœ¨ç”Ÿæˆé¢„æµ‹...", expanded=True) as status:
                try:
                    # ...ï¼ˆåŸæœ‰é¢„æµ‹å¤„ç†ä»£ç ä¸å˜ï¼‰
                    
                    # é¢„æµ‹å®Œæˆåä¿å­˜å®Œæ•´è®°å½•
                    history_id = create_history_entry(st.session_state.user_id)
                    if save_full_process_data(
                        st.session_state.user_id,
                        history_id,
                        st.session_state.raw_df,
                        st.session_state.cleaned_df,
                        cleaned_df[['äº§å“', 'è¯„è®º', 'ç³»ç»Ÿæ¨èæŒ‡æ•°']],
                        st.session_state.analysis_reports
                    ):
                        st.session_state.predicted_df = cleaned_df[['äº§å“', 'è¯„è®º', 'ç³»ç»Ÿæ¨èæŒ‡æ•°']]
                        status.update(label="âœ… é¢„æµ‹å®Œæˆï¼", state="complete")
                    
                except Exception as e:
                    status.update(label="âŒ é¢„æµ‹å‡ºé”™ï¼", state="error")
                    st.error(f"é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")
                    st.stop()

    # æ·±åº¦åˆ†ææ¨¡å—
    if st.session_state.predicted_df is not None:
        st.divider()
        st.subheader("æ·±åº¦åˆ†ææ¨¡å—")
    
        if st.button("ğŸ“Š ç”Ÿæˆäº§å“åˆ†ææŠ¥å‘Š", type="primary"):
            analysis_results = analyze_products(st.session_state.predicted_df)
            st.session_state.analysis_reports = analysis_results
            
            # è‡ªåŠ¨ä¿å­˜åˆ†ææŠ¥å‘Š
            history_id = create_history_entry(st.session_state.user_id)
            save_full_process_data(
                st.session_state.user_id,
                history_id,
                st.session_state.raw_df,
                st.session_state.cleaned_df,
                st.session_state.predicted_df,
                analysis_results
            )




# ====================== ä¸»ç¨‹åºå…¥å£ ======================
if __name__ == "__main__":
    # åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®åº“
    if 'model' not in st.session_state:
        try:
            # åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹
            st.session_state.model = joblib.load('model.joblib')
            st.session_state.tfidf = joblib.load('tfidf_vectorizer.joblib')
            category_mappings = joblib.load('category_mappings.joblib')
            st.session_state.region_mapping = category_mappings['region']
            st.session_state.product_mapping = category_mappings['product']
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    session_keys = ['logged_in', 'username', 'user_id', 'raw_df', 'cleaned_df', 'predicted_df']
    for key in session_keys:
        if key not in st.session_state:
            st.session_state[key] = None

    # é¡µé¢é…ç½®
    st.set_page_config(
        page_title="ç”µå•†ç”¨æˆ·è´­ä¹°å†³ç­–AIè¾…åŠ©æ”¯æŒç³»ç»Ÿ",
        layout="wide",
        page_icon="ğŸ›’",
        initial_sidebar_state="expanded"
    )
    
    # æµç¨‹æ§åˆ¶
    if not st.session_state.logged_in:
        auth_gate()
    else:
        main_interface()